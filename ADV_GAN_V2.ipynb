{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADV_GAN_V2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZH2TgiBYY-2",
        "colab_type": "text"
      },
      "source": [
        "#### This AdvGAN is an implementation of the following paper: ref: https://arxiv.org/pdf/1801.02610.pdf\n",
        "\n",
        "In this notebook we have been using MNIST however this advGAN architecture could be adapted to other datasets. Provided that the shape of the tensor graphs are adjusted accordingly.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYldGAtQAOcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bad978b-7463-4b0e-f953-3cf361bd6fd3"
      },
      "source": [
        "# Need mount drive as I work on google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfkn9srFAN6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This path below are specifically related to my directory on colab where I ran this project. \n",
        "#You'll need to set yours depending on whether you execute this code in local or in the cloud somewhere.\n",
        "\n",
        "\n",
        "!cd gdrive && cd 'My Drive' && mkdir weightsV2\n",
        "!cd gdrive && cd 'My Drive' && cd weightsV2 && mkdir generatorV2\n",
        "!cd gdrive && cd 'My Drive' && cd weightsV2 && mkdir discriminatorV2\n",
        "!cd gdrive && cd 'My Drive' && cd weightsV2 && mkdir targetV2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omj34i5A_WGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the discriminator architecture\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def discriminator(x, training):\n",
        "\twith tf.variable_scope('d_weights', reuse=tf.AUTO_REUSE):\n",
        "\t\t# input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\t\tfilters=8,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\t\tconv1 = tf.nn.leaky_relu(conv1, alpha=0.2)\n",
        "\n",
        "\t\t\n",
        "\t\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=conv1,\n",
        "\t\t\t\t\t\t\tfilters=16,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\tin1 = tf.contrib.layers.instance_norm(conv2)\n",
        "\t\tconv2 = tf.nn.leaky_relu(in1, alpha=0.2)\n",
        "\n",
        "\t\tconv3 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\tinputs=conv2,\n",
        "\t\t\t\t\t\t\tfilters=32,\n",
        "\t\t\t\t\t\t\tkernel_size=4,\n",
        "\t\t\t\t\t\t\tstrides=2,\n",
        "\t\t\t\t\t\t\tpadding=\"valid\",\n",
        "\t\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\t#in2 = tf.contrib.layers.instance_norm(conv3)\n",
        "\t\tin2 = tf.contrib.layers.instance_norm(conv3)\n",
        "\t\tconv3 = tf.nn.leaky_relu(in2, alpha=0.2)\n",
        "\t\tflat = tf.layers.flatten(conv3)\n",
        "\t\tlogits = tf.layers.dense(flat, 1)\n",
        "\n",
        "\t\tprobs = tf.nn.sigmoid(logits)\n",
        "\n",
        "\t\treturn logits, probs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvyyxJKG_sQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# helper functions for the generator\n",
        "\n",
        "\n",
        "def ConvInstNormRelu(x, filters, kernel_size=3, strides=1):\n",
        "\tConv = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tInstNorm = tf.contrib.layers.instance_norm(Conv)\n",
        "\n",
        "\treturn tf.nn.relu(InstNorm)\n",
        "\n",
        "\n",
        "\n",
        "def TransConvInstNormRelu(x, filters, kernel_size=3, strides=2):\n",
        "\tTransConv = tf.layers.conv2d_transpose(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tInstNorm = tf.contrib.layers.instance_norm(TransConv)\n",
        "\n",
        "\treturn tf.nn.relu(InstNorm)\n",
        "\n",
        "# helper function for residual block of 2 convolutions with same num filters\n",
        "# in the same style as ConvInstNormRelu\n",
        "def ResBlock(x, training, filters=32, kernel_size=3, strides=1):\n",
        "\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tconv1_norm = tf.layers.batch_normalization(conv1, training=training)\n",
        "\n",
        "\tconv1_relu = tf.nn.relu(conv1_norm)\n",
        "\n",
        "\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\tinputs=conv1_relu,\n",
        "\t\t\t\t\t\tfilters=filters,\n",
        "\t\t\t\t\t\tkernel_size=kernel_size,\n",
        "\t\t\t\t\t\tstrides=strides,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\tconv2_norm = tf.layers.batch_normalization(conv2, training=training)\n",
        "\n",
        "\n",
        "\treturn x + conv2_norm\n",
        "\n",
        "\n",
        "def generator(x, training):\n",
        "\twith tf.variable_scope('g_weights', reuse=tf.AUTO_REUSE):\n",
        "\t\t# input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\t# define first 3 conv + inst + relu layers\n",
        "\t\tc1 = ConvInstNormRelu(x, filters=8, kernel_size=3, strides=1)\n",
        "\t\td1 = ConvInstNormRelu(c1, filters=16, kernel_size=3, strides=2)\n",
        "\t\td2 = ConvInstNormRelu(d1, filters=32, kernel_size=3, strides=2)\n",
        "\n",
        "\t\t# define residual blocks\n",
        "\t\trb1 = ResBlock(d2, training, filters=32)\n",
        "\t\trb2 = ResBlock(rb1, training, filters=32)\n",
        "\t\trb3 = ResBlock(rb2, training, filters=32)\n",
        "\t\trb4 = ResBlock(rb3, training, filters=32)\n",
        "\n",
        "\t\t# upsample using conv transpose\n",
        "\t\tu1 = TransConvInstNormRelu(rb4, filters=16, kernel_size=3, strides=2)\n",
        "\t\tu2 = TransConvInstNormRelu(u1, filters=8, kernel_size=3, strides=2)\n",
        "\n",
        "\t\t# final layer block\n",
        "\t\tout = tf.layers.conv2d_transpose(\n",
        "\t\t\t\t\t\tinputs=u2,\n",
        "\t\t\t\t\t\tfilters=x.get_shape()[-1].value, # or 3 if RGB image\n",
        "\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\tstrides=1,\n",
        "\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\tactivation=None)\n",
        "\n",
        "\t\t# out = tf.contrib.layers.instance_norm(out)\n",
        "\n",
        "\t\treturn tf.nn.tanh(out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j43Rz8E_t3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "66b78888-b90f-45e3-e06d-20394a76a18d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Target:\n",
        "\tdef __init__(self, lr=0.001, epochs=10, n_input=28, n_classes=10, batch_size=16,\\\n",
        "\t\t\t\t\trestore=0):\n",
        "\t\tself.lr = lr\n",
        "\t\tself.epochs = epochs\n",
        "\t\tself.n_input = 28\n",
        "\t\tself.n_classes = 10\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.restore = restore\n",
        "\n",
        "\t\tos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "\t# randomly shuffle a dataset \n",
        "\tdef shuffle(self, X, Y):\n",
        "\t\trands = random.sample(range(X.shape[0]),X.shape[0])\n",
        "\t\treturn X[rands], Y[rands]\n",
        "\n",
        "\t# get the next batch based on x, y, and the iteration (based on batch_size)\n",
        "\tdef next_batch(self, X, Y, i, batch_size):\n",
        "\t\tidx = i * batch_size\n",
        "\t\tidx_n = i * batch_size + batch_size\n",
        "\t\treturn X[idx:idx_n], Y[idx:idx_n]\n",
        "\n",
        "\n",
        "\t# Now we define our target model (the model we aim to attack)\n",
        "\tdef ModelC(self, x):\n",
        "\t\twith tf.variable_scope('ModelC', reuse=tf.AUTO_REUSE):\n",
        "\t\t\t#input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "\t\t\tconv1 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\t\tinputs=x,\n",
        "\t\t\t\t\t\t\t\tfilters=32,\n",
        "\t\t\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\t\t\tactivation=tf.nn.relu)\n",
        "\t\t\t\n",
        "\t\t\tconv2 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\t\tinputs=conv1,\n",
        "\t\t\t\t\t\t\t\tfilters=32,\n",
        "\t\t\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\t\t\tactivation=tf.nn.relu)\n",
        "\n",
        "\t\t\tpool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "\t\t\tconv3 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\t\tinputs=pool1,\n",
        "\t\t\t\t\t\t\t\tfilters=64,\n",
        "\t\t\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\t\t\tactivation=tf.nn.relu)\n",
        "\n",
        "\t\t\tconv4 = tf.layers.conv2d(\n",
        "\t\t\t\t\t\t\t\tinputs=conv3,\n",
        "\t\t\t\t\t\t\t\tfilters=64,\n",
        "\t\t\t\t\t\t\t\tkernel_size=3,\n",
        "\t\t\t\t\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\t\t\t\t\tactivation=tf.nn.relu)\n",
        "\n",
        "\t\t\tpool2 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n",
        "\n",
        "\t\t\tpool2_flatten = tf.contrib.layers.flatten(pool2)\n",
        "\n",
        "\t\t\tfc1 = tf.layers.dense(inputs=pool2_flatten, units=200, activation=tf.nn.relu)\n",
        "\n",
        "\t\t\tfc2 = tf.layers.dense(inputs=fc1, units=200, activation=tf.nn.relu)\n",
        "\n",
        "\t\t\tlogits = tf.layers.dense(inputs=fc2, units=self.n_classes, activation=None)\n",
        "\n",
        "\t\t\tprobs = tf.nn.softmax(logits)\n",
        "\n",
        "\t\t\treturn logits, probs\n",
        "\n",
        "\n",
        "\n",
        "\tdef train(self, X, Y, X_test, Y_test):\n",
        "\t\t# define placeholders for input data\n",
        "\t\tx = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]])\n",
        "\t\ty = tf.placeholder(tf.float32, [None, self.n_classes])\n",
        "\n",
        "\t\t# define compute graph\n",
        "\t\tlogits, _ = self.ModelC(x)\n",
        "\n",
        "\t\t# define cost\n",
        "\t\tcost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
        "\n",
        "\t\t# optimizer\n",
        "\t\toptimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(cost)\n",
        "\n",
        "\t\tsaver = tf.train.Saver()\n",
        "\n",
        "\t\t# Initializing the variables\n",
        "\t\tinit = tf.global_variables_initializer()\n",
        "\n",
        "\t\tsess = tf.Session()\n",
        "\t\tsess.run(init)\n",
        "\n",
        "\t\ttotal_batch = int(X.shape[0] / self.batch_size)\n",
        "\n",
        "\t\tfor epoch in range(1, self.epochs + 1):\n",
        "\t\t\tavg_cost = 0.\n",
        "\n",
        "\t\t\tfor i in range(total_batch):\n",
        "\t\t\t\tbatch_x, batch_y = self.next_batch(X, Y, i, self.batch_size)\n",
        "\t\t\t\t\n",
        "\t\t\t\t_, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
        "\n",
        "\t\t\t\tavg_cost += c / total_batch\n",
        "\n",
        "\t\t\tprint(\"Epoch:\", '%04d' % (epoch), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
        "\n",
        "\t\t# Test model\n",
        "\t\tcorrect_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "\n",
        "\t\t# Calculate accuracy\n",
        "\t\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "\t\taccs = []\n",
        "\n",
        "\t\ttotal_test_batch = int(X_test.shape[0] / self.batch_size)\n",
        "\t\tfor i in range(total_test_batch):\n",
        "\t\t\tbatch_x, batch_y = self.next_batch(X_test, Y_test, i, self.batch_size)\n",
        "\t\t\t#batch_x = dataset.train.permute(batch_x, idxs)\n",
        "\t\t\taccs.append(accuracy.eval({x: batch_x, y: batch_y}, session=sess))\n",
        "\n",
        "\t\tprint('accuracy of test set: {}'.format(sum(accs) / len(accs)))\n",
        "\n",
        "\t\tsaver.save(sess, \"./gdrive/My Drive/weightsV2/targetV2/weights_target_modelV2.ckpt\")\n",
        "\t\tsess.close() \n",
        "\n",
        "        \n",
        "\n",
        "# LOADING MNIST\n",
        "if __name__ == '__main__':\n",
        "\t(X,y), (X_test,y_test) = mnist.load_data()\n",
        "\tX = np.divide(X, 255.0)\n",
        "\tX_test = np.divide(X_test, 255.0)\n",
        "\tX = X.reshape(X.shape[0], 28, 28, 1)\n",
        "\tX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\ty = to_categorical(y, num_classes=10)\n",
        "\ty_test = to_categorical(y_test, num_classes=10)\n",
        "\tcnn = Target()\n",
        "\tcnn.train(X, y, X_test, y_test) # We train the model # MAKE SURE THE TARGET MODEL IS TRAINED BEFORE MOVING FORWARD !!!!"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0705 12:12:00.968019 140625910572928 deprecation.py:323] From <ipython-input-3-7aeb4408afe4>:50: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0705 12:12:00.974291 140625910572928 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0705 12:12:01.226019 140625910572928 deprecation.py:323] From <ipython-input-3-7aeb4408afe4>:59: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "W0705 12:12:02.413367 140625910572928 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0705 12:12:02.415286 140625910572928 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0705 12:12:02.666357 140625910572928 deprecation.py:323] From <ipython-input-3-7aeb4408afe4>:79: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost= 0.111219544\n",
            "Epoch: 0002 cost= 0.045070848\n",
            "Epoch: 0003 cost= 0.031019737\n",
            "Epoch: 0004 cost= 0.024746449\n",
            "Epoch: 0005 cost= 0.019493017\n",
            "Epoch: 0006 cost= 0.017853546\n",
            "Epoch: 0007 cost= 0.015687718\n",
            "Epoch: 0008 cost= 0.014743138\n",
            "Epoch: 0009 cost= 0.013820874\n",
            "Epoch: 0010 cost= 0.011349213\n",
            "accuracy of test set: 0.9902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oChbFQg_8sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os, sys\n",
        "import random\n",
        "\n",
        "adversarials =[] # create an empty list to append adversarial images \n",
        "\n",
        "\n",
        "# randomly shuffle a dataset \n",
        "def shuffle(X, Y):\n",
        "\trands = random.sample(range(X.shape[0]),X.shape[0])\n",
        "\treturn X[rands], Y[rands]\n",
        "\n",
        "# get the next batch based on x, y, and the iteration (based on batch_size)\n",
        "def next_batch(X, Y, i, batch_size):\n",
        "\tidx = i * batch_size\n",
        "\tidx_n = i * batch_size + batch_size\n",
        "\treturn X[idx:idx_n], Y[idx:idx_n]\n",
        "\n",
        "# loss function to encourage misclassification after perturbation\n",
        "def adv_loss(preds, labels, is_targeted):\n",
        "\treal = tf.reduce_sum(labels * preds, 1)\n",
        "\tother = tf.reduce_max((1 - labels) * preds - (labels * 10000), 1)\n",
        "\tif is_targeted:\n",
        "\t\treturn tf.reduce_sum(tf.maximum(0.0, other - real))\n",
        "\treturn tf.reduce_sum(tf.maximum(0.0, real - other))\n",
        "\n",
        "# loss function to influence the perturbation to be as close to 0 as possible\n",
        "def perturb_loss(preds, thresh=0.3):\n",
        "\tzeros = tf.zeros((tf.shape(preds)[0]))\n",
        "\treturn tf.reduce_mean(tf.maximum(zeros, tf.norm(tf.reshape(preds, (tf.shape(preds)[0], -1)), axis=1) - thresh))\n",
        "\n",
        "\n",
        "# function that defines ops, graphs, and training procedure for AdvGAN framework\n",
        "def AdvGAN(X, y, X_test, y_test, epochs=50, batch_size=128, target=-1, thresh = 0.3):\n",
        "\t# placeholder definitions\n",
        "\tx_pl = tf.placeholder(tf.float32, [None, X.shape[1], X.shape[2], X.shape[3]]) # image placeholder\n",
        "\tt = tf.placeholder(tf.float32, [None, y.shape[-1]]) # target placeholder\n",
        "\tis_training = tf.placeholder(tf.bool, [])\n",
        "\n",
        "\t#-----------------------------------------------------------------------------------\n",
        "\t# MODEL DEFINITIONS\n",
        "\tis_targeted = False\n",
        "\tif target in range(0, y.shape[-1]):\n",
        "\t\tis_targeted = True\n",
        "\n",
        "\t# gather target model\n",
        "\tf = Target()\n",
        "\n",
        "\t# generate perturbation, add to original input image(s)\n",
        "\tperturb = tf.clip_by_value(generator(x_pl, is_training), -thresh, thresh)\n",
        "\tx_perturbed = perturb + x_pl\n",
        "\tx_perturbed = tf.clip_by_value(x_perturbed, 0, 1)\n",
        "\n",
        "\t# pass real and perturbed image to discriminator and the target model\n",
        "\td_real_logits, d_real_probs = discriminator(x_pl, is_training)\n",
        "\td_fake_logits, d_fake_probs = discriminator(x_perturbed, is_training)\n",
        "\t\n",
        "\t# pass real and perturbed images to the model we are trying to fool\n",
        "\tf_real_logits, f_real_probs = f.ModelC(x_pl)\n",
        "\tf_fake_logits, f_fake_probs = f.ModelC(x_perturbed)\n",
        "\n",
        "\t\n",
        "\t# generate labels for discriminator (optionally smooth labels for stability)\n",
        "\tsmooth = 0.0\n",
        "\td_labels_real = tf.ones_like(d_real_probs) * (1 - smooth)\n",
        "\td_labels_fake = tf.zeros_like(d_fake_probs)\n",
        "\n",
        "\t#-----------------------------------------------------------------------------------\n",
        "\t# LOSS DEFINITIONS\n",
        "\t# discriminator loss\n",
        "\td_loss_real = tf.losses.mean_squared_error(predictions=d_real_probs, labels=d_labels_real)\n",
        "\td_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=d_labels_fake)\n",
        "\td_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "\t# generator loss\n",
        "\tg_loss_fake = tf.losses.mean_squared_error(predictions=d_fake_probs, labels=tf.ones_like(d_fake_probs))\n",
        "\n",
        "\t# perturbation loss (minimize overall perturbation)\n",
        "\tl_perturb = perturb_loss(perturb, thresh)\n",
        "\n",
        "\t# adversarial loss (encourage misclassification)\n",
        "\tl_adv = adv_loss(f_fake_probs, t, is_targeted)\n",
        "\n",
        "\t# weights for generator loss function\n",
        "    # This weight below alpha and beta are very important hyperparameters for the ADV_GAN to work properly\n",
        "    # They basically define the trade-off for the generator loss function. THE GENERATOR HAS 3 DIFFERENTS LOSS !\n",
        "\talpha = 2.0\n",
        "\tbeta = 5.0\n",
        "\tg_loss = l_adv + alpha*g_loss_fake + beta*l_perturb \n",
        "\n",
        "\t# ----------------------------------------------------------------------------------\n",
        "\t# gather variables for training/restoring\n",
        "\tt_vars = tf.trainable_variables()\n",
        "\tf_vars = [var for var in t_vars if 'ModelC' in var.name]\n",
        "\td_vars = [var for var in t_vars if 'd_' in var.name]\n",
        "\tg_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='g_weights')\n",
        "\n",
        "\t# define optimizers for discriminator and generator\n",
        "\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\twith tf.control_dependencies(update_ops):\n",
        "\t\td_opt = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n",
        "\t\tg_opt = tf.train.AdamOptimizer(learning_rate=0.001).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "\t# create saver objects for the target model, generator, and discriminator\n",
        "\tsaver = tf.train.Saver(f_vars)\n",
        "\tg_saver = tf.train.Saver(g_vars)\n",
        "\td_saver = tf.train.Saver(d_vars)\n",
        "\n",
        "\tinit  = tf.global_variables_initializer()\n",
        "\n",
        "\tsess  = tf.Session()\n",
        "\tsess.run(init)\n",
        "\n",
        "\t# load the pretrained target model\n",
        "\ttry:\n",
        "\t\tsaver.restore(sess, \"./gdrive/My Drive/weightsV2/targetV2/weights_target_modelV2.ckpt\")\n",
        "\texcept:\n",
        "\t\tprint(\"make sure to train the target model first...\") # IMPORTANT DO NOT FORGET THAT \n",
        "\t\tsys.exit(1)\n",
        "\n",
        "\ttotal_batches = int(X.shape[0] / batch_size)\n",
        "\n",
        "\tfor epoch in range(0, epochs):\n",
        "\n",
        "\t\tX, y = shuffle(X, y)\n",
        "\t\tloss_D_sum = 0.0\n",
        "\t\tloss_G_fake_sum = 0.0\n",
        "\t\tloss_perturb_sum = 0.0\n",
        "\t\tloss_adv_sum = 0.0\n",
        "\n",
        "\t\tfor i in range(total_batches):\n",
        "\n",
        "\t\t\tbatch_x, batch_y = next_batch(X, y, i, batch_size)\n",
        "\n",
        "\t\t\t# if targeted, create one hot vectors of the target\n",
        "\t\t\tif is_targeted:\n",
        "\t\t\t\ttargets = np.full((batch_y.shape[0],), target)\n",
        "\t\t\t\tbatch_y = np.eye(y.shape[-1])[targets]\n",
        "\n",
        "\t\t\t# train the discriminator first n times\n",
        "            # HERE WE ARE TRAINING THE DISCRIMINATOR 1 TIME\n",
        "\t\t\tfor _ in range(1):\n",
        "\t\t\t\t_, loss_D_batch = sess.run([d_opt, d_loss], feed_dict={x_pl: batch_x, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   is_training: True})\n",
        "\n",
        "\t\t\t# train the generator n times\n",
        "            # HERE WE ARE TRAINING THE GENERATOR 2 TIMES => We want more weight of the generator.\n",
        "\t\t\tfor _ in range(2):\n",
        "\t\t\t\t_, loss_G_fake_batch, loss_adv_batch, loss_perturb_batch = \\\n",
        "\t\t\t\t\t\t\t\t\tsess.run([g_opt, g_loss_fake, l_adv, l_perturb], \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfeed_dict={x_pl: batch_x, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   t: batch_y, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   is_training: True})\n",
        "\t\t\tloss_D_sum += loss_D_batch\n",
        "\t\t\tloss_G_fake_sum += loss_G_fake_batch\n",
        "\t\t\tloss_perturb_sum += loss_perturb_batch\n",
        "\t\t\tloss_adv_sum += loss_adv_batch\n",
        "\n",
        "\t\tprint(\"epoch %d:\\nloss_D: %.3f, loss_G_fake: %.3f, \\\n",
        "\t\t\t\t\\nloss_perturb: %.3f, loss_adv: %.3f, \\n\" %\n",
        "\t\t\t\t(epoch + 1, loss_D_sum/total_batches, loss_G_fake_sum/total_batches,\n",
        "\t\t\t\tloss_perturb_sum/total_batches, loss_adv_sum/total_batches))\n",
        "\n",
        "\t\tif epoch % 10 == 0:\n",
        "\t\t\tg_saver.save(sess, \"gdrive/My Drive/weightsV2/generatorV2/weights_genV2.ckpt\")\n",
        "\t\t\td_saver.save(sess, \"gdrive/My Drive/weightsV2/discriminatorV2/weights_discV2.ckpt\")\n",
        "\n",
        "\t# evaluate the test set\n",
        "\tcorrect_prediction = tf.equal(tf.argmax(f_fake_probs, 1), tf.argmax(t, 1))\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\taccs = []\n",
        "\ttotal_batches_test = int(X_test.shape[0] / batch_size)\n",
        "\tfor i in range(total_batches_test):\n",
        "\t\tbatch_x, batch_y = next_batch(X_test, y_test, i, batch_size)\n",
        "\t\tacc, x_pert = sess.run([accuracy, x_perturbed], feed_dict={x_pl: batch_x, t: batch_y, is_training: False})\n",
        "\t\tadversarials.append(x_pert)  # append adversarial images    \n",
        "\n",
        "\n",
        "\tprint('finished training, saving weights')\n",
        "\tg_saver.save(sess, \"gdrive/My Drive/weightsV2/generatorV2/weights_genV2.ckpt\")\n",
        "\td_saver.save(sess, \"gdrive/My Drive/weightsV2/discriminatorV2/weights_discV2.ckpt\")\n",
        "                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZURx758FD-VV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "5c8fb803-10c6-4d3c-fade-28b651912aae"
      },
      "source": [
        "tf.reset_default_graph() # Reset the default graph\n",
        "AdvGAN(X, y, X_test, y_test, batch_size=128, epochs=7, target=-1) # Running the advGAN attack"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 5.718, loss_adv: 10.584, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.947, loss_adv: 1.070, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.254, loss_adv: 0.807, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.977, loss_adv: 0.711, \n",
            "\n",
            "epoch 5:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.815, loss_adv: 0.624, \n",
            "\n",
            "epoch 6:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.685, loss_adv: 0.590, \n",
            "\n",
            "epoch 7:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.589, loss_adv: 0.530, \n",
            "\n",
            "finished training, saving weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB9q7gg7MbiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "77da696d-79b3-4919-afcc-de9cb85cf268"
      },
      "source": [
        "# plotting the just 2 generated adversarial versus their respective clean images:\n",
        "\n",
        "adv_images = np.array(adversarials).reshape(78*128,28,28,1)\n",
        "\n",
        "f, axarr = plt.subplots(2,2)\n",
        "axarr[0,0].imshow(np.squeeze(adv_images [0]), cmap='Greys_r')\n",
        "axarr[0,1].imshow(np.squeeze(X_test[0]), cmap='Greys_r')\n",
        "axarr[1,0].imshow(np.squeeze(adv_images [45]), cmap='Greys_r')\n",
        "axarr[1,1].imshow(np.squeeze(X_test[45]), cmap='Greys_r')\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe5579b9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRMf/Ad85zynGfpUFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lji5OAgKM_-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08831726-2722-4221-91a4-52c1d093bfba"
      },
      "source": [
        "threshold = np.linspace(0.0,1,7) # setting different threshold values => The threshold here defined the magnitude of the pertubation. \n",
        "adv_imarray = np.zeros((len(threshold),78*128,28,28,1)) # creating empting array to retrieve all the adversarial per threshold values\n",
        "for i in range (len(threshold)):\n",
        "    tf.reset_default_graph() \n",
        "    AdvGAN(X, y, X_test, y_test, batch_size=128, epochs=5, target=-1, thresh =threshold[i])\n",
        "adv_imarray[i] = np.array(adversarials).reshape(78*128,28,28,1)\n",
        "  \n",
        "# We set 7 different threshold values and there 5 epochs per attack. \n",
        "# We can observe for each epochs how the loss_pertub and loss_adv change as we increase the threshold values below:"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 0.000, loss_adv: 127.000, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 0.000, loss_adv: 127.000, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 0.000, loss_adv: 127.002, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 0.000, loss_adv: 127.000, \n",
            "\n",
            "epoch 5:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 0.000, loss_adv: 127.002, \n",
            "\n",
            "finished training, saving weights\n",
            "epoch 1:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 4.013, loss_adv: 60.487, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.668, loss_adv: 24.557, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.361, loss_adv: 18.775, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.194, loss_adv: 16.890, \n",
            "\n",
            "epoch 5:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.087, loss_adv: 15.813, \n",
            "\n",
            "finished training, saving weights\n",
            "epoch 1:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 5.627, loss_adv: 7.465, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.809, loss_adv: 1.066, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.160, loss_adv: 0.780, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.862, loss_adv: 0.678, \n",
            "\n",
            "epoch 5:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.709, loss_adv: 0.601, \n",
            "\n",
            "finished training, saving weights\n",
            "epoch 1:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 7.295, loss_adv: 3.949, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.621, loss_adv: 1.098, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.950, loss_adv: 0.772, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.699, loss_adv: 0.619, \n",
            "\n",
            "epoch 5:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.546, loss_adv: 0.576, \n",
            "\n",
            "finished training, saving weights\n",
            "epoch 1:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 6.373, loss_adv: 2.881, \n",
            "\n",
            "epoch 2:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 3.151, loss_adv: 0.988, \n",
            "\n",
            "epoch 3:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.682, loss_adv: 0.802, \n",
            "\n",
            "epoch 4:\n",
            "loss_D: 0.500, loss_G_fake: 0.250, \t\t\t\t\n",
            "loss_perturb: 2.428, loss_adv: 0.686, \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
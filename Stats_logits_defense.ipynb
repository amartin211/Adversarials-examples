{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stats_logits_defense.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov9eG0CfOlp3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "be6fcc81-c91e-4581-8c22-1a263590b3e1"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C86NBO9yOyfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# changing y labels from a scalar to a one hot encoder representation\n",
        "\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbPmXHPPPB1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "outputId": "06e9587f-c52c-434e-cfa9-7a1489ac77e1"
      },
      "source": [
        "# Our base model \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization(axis=-1)\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "BatchNormalization(axis=-1)\n",
        "model.add(Conv2D(64,(3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization(axis=-1)\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "# Fully connected layer\n",
        "\n",
        "BatchNormalization()\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10))\n",
        "\n",
        "\n",
        "model.add(Activation('softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 13:50:42.381972 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0704 13:50:42.406879 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0704 13:50:42.412402 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0704 13:50:42.439077 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0704 13:50:42.485765 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0704 13:50:42.493599 140095235344256 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 594,922\n",
            "Trainable params: 594,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPfvpLEQPEVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0e95cd7c-1200-4d09-d705-64d8eb33ffe5"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# data augmentation with spacial modifications\n",
        "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.08, zoom_range=0.08)\n",
        "\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "train_generator = gen.flow(x_train, y_train, batch_size=64)\n",
        "test_generator = test_gen.flow(x_test, y_test, batch_size=64)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 13:50:46.874651 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0704 13:50:46.882251 140095235344256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5ipiUXVPEM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d5a5e56-0d1a-4259-8f7a-cb72732caa15"
      },
      "source": [
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
        "                    validation_data=test_generator, validation_steps=10000//64)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 13:50:49.553035 140095235344256 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "937/937 [==============================] - 21s 23ms/step - loss: 0.1991 - acc: 0.9364 - val_loss: 0.0303 - val_acc: 0.9904\n",
            "Epoch 2/5\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 0.0623 - acc: 0.9809 - val_loss: 0.0200 - val_acc: 0.9924\n",
            "Epoch 3/5\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 0.0456 - acc: 0.9862 - val_loss: 0.0225 - val_acc: 0.9918\n",
            "Epoch 4/5\n",
            "937/937 [==============================] - 18s 19ms/step - loss: 0.0427 - acc: 0.9872 - val_loss: 0.0165 - val_acc: 0.9948\n",
            "Epoch 5/5\n",
            "937/937 [==============================] - 19s 20ms/step - loss: 0.0338 - acc: 0.9897 - val_loss: 0.0160 - val_acc: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6a54d9b2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvcXpO_hPJKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "36e2a73d-a46c-42a1-d28f-593c63ae5507"
      },
      "source": [
        "# Installing foolbox package (adversarial library)\n",
        "\n",
        "!pip install foolbox"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: foolbox in /usr/local/lib/python3.6/dist-packages (1.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox) (41.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from foolbox) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.16.4)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.6/dist-packages (from foolbox) (2.1.11)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->foolbox) (2019.6.16)\n",
            "Requirement already satisfied: gitdb2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from GitPython->foolbox) (2.0.5)\n",
            "Requirement already satisfied: smmap2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from gitdb2>=2.0.0->GitPython->foolbox) (2.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvvwBrX-PLb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import foolbox\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import backend\n",
        "from keras.models import load_model\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "from foolbox.attacks import SaliencyMapAttack\n",
        "from foolbox.criteria import Misclassification\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cAPHDvyPNjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6c1c7e2-ac88-4a56-9107-985b37ce0ad8"
      },
      "source": [
        "_,(images, labels) = mnist.load_data()\n",
        "images = images.reshape(10000,28,28,1)\n",
        "images= images.astype('float32')\n",
        "images /= 255\n",
        "images[1].shape\n",
        "labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zXoNvzPPShn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to retrieve the logits (argument to softmax layers) from our model \n",
        "\n",
        "\n",
        "def get_softmax_args(X):\n",
        "    if np.ndim(X)==3:\n",
        "        X = X.reshape(1,28,28,1)\n",
        "        x = model.output.op.inputs[-1]\n",
        "        func = K.function([model.input] + [K.learning_phase()], [x])\n",
        "        softmax_output = np.array(func([X, 0.]))\n",
        "    else:\n",
        "        x = model.output.op.inputs[-1]\n",
        "        func = K.function([model.input] + [K.learning_phase()], [x])\n",
        "        softmax_output = np.array(func([X, 0.]))\n",
        "    return np.squeeze(softmax_output)\n",
        "\n",
        "\n",
        "# return a vector of shape (number of images * number of attacks, number of outputs(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4E1aVCIPXKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "d8321761-2ecc-4b67-e478-5dfce3ff9a6c"
      },
      "source": [
        "\n",
        "fmodel = foolbox.models.KerasModel(model, bounds=(0,1)) # creating a foolbox model for an attack via KerasModel\n",
        "\n",
        "# Setting up a Newton attack with Misclassification criteria (vs targeted attack)\n",
        "attack=foolbox.attacks.NewtonFoolAttack(fmodel,criterion=Misclassification())\n",
        "\n",
        "# number of images to attacks\n",
        "num_sample = 1000\n",
        "\n",
        "# setting an empty list to retrieve adversarial images.\n",
        "adv_input = []\n",
        "\n",
        "\n",
        "# theta correspond to the number of different thetas (magnitude of the pertubation) we want to run the attack with.\n",
        "# Below, we want 20 different thetas from 0 (no pertubation) to 0.5.\n",
        "theta = np.linspace(0,.5,20)\n",
        "\n",
        "# looping across the 20 thetas values:\n",
        "for i in range (len(theta)):\n",
        "    \n",
        "    # looing across the number of images to attack\n",
        "    for j in range (len(x_test[:num_sample])):\n",
        "    \n",
        "        adversarial_all = attack(x_test[j],labels[j],eta=theta[i]) # running the attacks\n",
        "        \n",
        "        # if the attack is not effective => return the intial clean image instead\n",
        "        if np.size(adversarial_all) == 1:\n",
        "            adversarial_all = x_test[j].reshape(1,28,28,1)\n",
        "            adv_input.append(adversarial_all)\n",
        "        else:\n",
        "        # if the attack is successful return the adversarial images\n",
        "            adversarial_all = np.array(adversarial_all).reshape(1,28,28,1) # reshaping it for model prediction\n",
        " \n",
        "            adv_input.append(adversarial_all)\n",
        "    \n",
        "    \n",
        "# Note that here we run 20 NewtonFool attacks (one for each thetas) on 1000 images.\n",
        "# We want a vector of shape (20*1000,28,28,1)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/foolbox/attacks/base.py:148: UserWarning: NewtonFoolAttack did not find an adversarial, maybe the model or the criterion is not supported by this attack.\n",
            "  ' attack.'.format(self.name()))\n",
            "/usr/local/lib/python3.6/dist-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n",
            "  warnings.warn('Not running the attack because the original input'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K-jC0BjRFCY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "652d455e-3076-4350-db84-054b50af6062"
      },
      "source": [
        "# Retrieving logits from clean and adversarial samples\n",
        "\n",
        "samples_advs = np.array(adv_input).reshape(len(adv_input),28,28,1)\n",
        "args_clean = get_softmax_args(x_test)\n",
        "args_advs = get_softmax_args(samples_advs)\n",
        "args_advs.shape"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH_yhHoLnEo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# this function calculates the relative differences of logits scores as per the paper :\n",
        "#The Odds are Odd: A Statistical Test for Detecting Adversarial Examples, Kevin Roth,Yannic Kilcher, Thomas Hofmann.\n",
        "\n",
        "\n",
        "def advs_latent_diff_new(args_advs):\n",
        "\n",
        "    adv_reor = args_advs.reshape(len(true_test),len(theta),10)\n",
        "\n",
        "    diff_advs = []\n",
        "\n",
        "    #for j in range(10):\n",
        "    for i in range(len(adv_reor)):\n",
        "        for k in range (adv_reor.shape[1]):\n",
        "            for l in range (10):\n",
        "                diff_advs.append(np.mean(adv_reor[i][k] - adv_reor[i][k][l],axis=-1))\n",
        "                \n",
        "    difference_advs = np.array(diff_advs) # we append these scores differences in a numpy array.       \n",
        "    return difference_advs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Zp14ClnH_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as above but for clean examples \n",
        "\n",
        "def true_latent_diff_new(args_clean):\n",
        "    diff_true = [] \n",
        "    \n",
        "    for i in range(len(args_clean)):\n",
        "        for l in range(10):\n",
        "            diff_true.append(np.mean(args_clean[i] - args_clean[i][l],axis=-1))\n",
        "                \n",
        "    difference_clean = np.array(diff_true)\n",
        "    return difference_clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUt6IJ4BWKEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9b840e5f-427a-4f0a-c66a-0f88d99ce948"
      },
      "source": [
        "\n",
        "# getting logits differences for clean samples.\n",
        "true_test = get_softmax_args(x_test[:num_sample])\n",
        "xtest_diff = true_latent_diff_new(true_test).reshape(num_sample,10)\n",
        "\n",
        "print(xtest_diff.shape)\n",
        "\n",
        "\n",
        "\n",
        "# getting logits differences for adversarials samples.\n",
        "advs_diff = advs_latent_diff_new(args_advs)\n",
        "resh = np.array(advs_diff).reshape(len(true_test),len(theta),10)\n",
        "advs_diff_redim = np.mean(resh,axis=1)\n",
        "\n",
        "print(advs_diff_redim.shape)\n",
        "print(resh.shape)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "(1000, 10)\n",
            "(1000, 20, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A51mczdGRl5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "0eb79436-730e-4c49-b25e-85d9d78ed9c8"
      },
      "source": [
        "# Training a classifier with adversarial logits differences defined above.\n",
        "\n",
        "from sklearn import svm\n",
        "rbf_svc = svm.SVC(kernel='rbf')\n",
        "rbf_svc.fit(advs_diff_redim, labels[:num_sample]) # TRAINED ONLY WITH THE LOGITS DIFERENCES OF THE NEWTOW-FOOL ATTACK"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUs6QgqLP6cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this fonction first calcule the Z_score of the logits difference and then add a condition to define whether it is an adversarial or a clean examples.\n",
        "\n",
        "\n",
        "def advs_detection_and_correction(testset, threshold):\n",
        "    from scipy import stats\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    cl = []\n",
        "    L2_dist = []\n",
        "    for i in range(len(testset)):\n",
        "        cl.append(np.max(stats.zscore(testset[i]) - threshold)) # Calculate the Z_score stats of the logits differences. \n",
        "    index_clean = []\n",
        "    index_adv = []\n",
        "    for i in range(len(cl)):\n",
        "        if cl[i]>=0: \n",
        "            index_clean.append(i)#if max Z_score for a particular image is above 0 then it is considered clean and we keep the index in the index_clean list\n",
        "        else:\n",
        "            index_adv.append(i)# if not then it is an adversarial examples and we keep the index in index_adv.\n",
        "\n",
        "    # calculate prediction if input is clean with our initial model.       \n",
        "    pred_y = model.predict_classes(x_test[index_clean])\n",
        "    acc_clean = accuracy_score(labels[index_clean],pred_y)\n",
        "    \n",
        "    \n",
        "    # calculate prediction if input is adversarial with our SVM classifier trained on adversarial logits.  \n",
        "    pred_adv = rbf_svc.predict(testset[index_adv])\n",
        "    acc_adv = accuracy_score(labels[index_adv],pred_adv)\n",
        "  \n",
        "    return acc_clean, acc_adv,len(index_adv),len(index_clean) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS7KajGKP8u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the accuracy for a mixture of adversarial and clean examples.\n",
        "\n",
        "\n",
        "def global_accuracy(args_difference):\n",
        "    acc_clean, acc_pert, n_adv, n_clean = advs_detection_and_correction(args_difference,threshold = 1.054) # need to find the best threshold but 1.054 is good\n",
        "    \n",
        "    global_acc = (n_clean/len(args_difference))*acc_clean + (n_adv/len(args_difference))*acc_pert\n",
        "\n",
        "    return global_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8G8bMSRP-uD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "32801772-4a29-484b-83a7-9178c53676d7"
      },
      "source": [
        "print('Accuracy on 100% clean test set is ' + str(global_accuracy(xtest_diff)))\n",
        "\n",
        "for i in range (resh.shape[1]):\n",
        "    print('Accuracy on 100% advs test set is ' + str(global_accuracy(resh[:,i,:])))"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on 100% clean test set is 0.747\n",
            "Accuracy on 100% advs test set is 0.903\n",
            "Accuracy on 100% advs test set is 0.883\n",
            "Accuracy on 100% advs test set is 0.907\n",
            "Accuracy on 100% advs test set is 0.876\n",
            "Accuracy on 100% advs test set is 0.9\n",
            "Accuracy on 100% advs test set is 0.925\n",
            "Accuracy on 100% advs test set is 0.913\n",
            "Accuracy on 100% advs test set is 0.903\n",
            "Accuracy on 100% advs test set is 0.896\n",
            "Accuracy on 100% advs test set is 0.906\n",
            "Accuracy on 100% advs test set is 0.887\n",
            "Accuracy on 100% advs test set is 0.897\n",
            "Accuracy on 100% advs test set is 0.894\n",
            "Accuracy on 100% advs test set is 0.919\n",
            "Accuracy on 100% advs test set is 0.882\n",
            "Accuracy on 100% advs test set is 0.897\n",
            "Accuracy on 100% advs test set is 0.909\n",
            "Accuracy on 100% advs test set is 0.944\n",
            "Accuracy on 100% advs test set is 0.833\n",
            "Accuracy on 100% advs test set is 0.935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za5sBlAwSFA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c7fbe696-64c4-4835-e73e-9f180a07fb26"
      },
      "source": [
        "L2_dist = []\n",
        "score_adv = []\n",
        "\n",
        "reshaped_adv = np.array(adv_input).reshape(len(theta)*num_sample,28,28,1)\n",
        "adv_test = np.zeros((len(theta),num_sample,28,28,1))\n",
        "for i in range(len(theta)):\n",
        "    adv_test[i] = reshaped_adv[i*num_sample:(i+1)*num_sample]\n",
        "    score_adv.append(model.evaluate(adv_test[i], y_test[:num_sample])[1]) # Calculate the accuracy of our model with NO defense.\n",
        "    L2_dist.append((1/num_sample)*np.sum((adv_test[i] - x_test[:num_sample])**2)) # Calculate the L2 distance."
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 74us/step\n",
            "1000/1000 [==============================] - 0s 70us/step\n",
            "1000/1000 [==============================] - 0s 83us/step\n",
            "1000/1000 [==============================] - 0s 74us/step\n",
            "1000/1000 [==============================] - 0s 72us/step\n",
            "1000/1000 [==============================] - 0s 66us/step\n",
            "1000/1000 [==============================] - 0s 70us/step\n",
            "1000/1000 [==============================] - 0s 69us/step\n",
            "1000/1000 [==============================] - 0s 68us/step\n",
            "1000/1000 [==============================] - 0s 69us/step\n",
            "1000/1000 [==============================] - 0s 68us/step\n",
            "1000/1000 [==============================] - 0s 72us/step\n",
            "1000/1000 [==============================] - 0s 68us/step\n",
            "1000/1000 [==============================] - 0s 68us/step\n",
            "1000/1000 [==============================] - 0s 67us/step\n",
            "1000/1000 [==============================] - 0s 79us/step\n",
            "1000/1000 [==============================] - 0s 67us/step\n",
            "1000/1000 [==============================] - 0s 70us/step\n",
            "1000/1000 [==============================] - 0s 71us/step\n",
            "1000/1000 [==============================] - 0s 68us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVdtC0iFShVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the accuracy of our model WITH the logits detection and correction defense and appending it for plotting.\n",
        "\n",
        "advs_accuracy = []\n",
        "\n",
        "for i in range (resh.shape[1]):\n",
        "    advs_accuracy.append(global_accuracy(resh[:,i,:]))\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfU_0QSqZ6uX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "846cf301-30dc-475d-df0b-39a162cf9ad7"
      },
      "source": [
        "# plotting the two lines for comparison.\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = plt.subplot(111)\n",
        "#plt.plot(L2_dist,score_adv,'--')\n",
        "ax.plot(L2_dist,score_adv, \"r--\", label=\"NewtonFool clean\")\n",
        "ax.plot(L2_dist,advs_accuracy, \"b--\", label=\"NewtonFool log-odds corrected\")\n",
        "ax.legend(loc='best',prop={'size': 12})\n",
        "plt.xlabel('L2_distance')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy vs L2 distance')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHxCAYAAADDUqDRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}